{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Package\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width    variety  label\n",
       "0             5.1          3.5           1.4          0.2     Setosa      0\n",
       "1             4.9          3.0           1.4          0.2     Setosa      0\n",
       "2             4.7          3.2           1.3          0.2     Setosa      0\n",
       "3             4.6          3.1           1.5          0.2     Setosa      0\n",
       "4             5.0          3.6           1.4          0.2     Setosa      0\n",
       "..            ...          ...           ...          ...        ...    ...\n",
       "145           6.7          3.0           5.2          2.3  Virginica      2\n",
       "146           6.3          2.5           5.0          1.9  Virginica      2\n",
       "147           6.5          3.0           5.2          2.0  Virginica      2\n",
       "148           6.2          3.4           5.4          2.3  Virginica      2\n",
       "149           5.9          3.0           5.1          1.8  Virginica      2\n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal.length    float64\n",
       "sepal.width     float64\n",
       "petal.length    float64\n",
       "petal.width     float64\n",
       "variety          object\n",
       "label             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cek tipedata df\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal.length', 'sepal.width', 'petal.length', 'petal.width', 'variety',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Akses kolom df\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9, 5.4, 4.8, 4.8,\n",
       "       4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5. ,\n",
       "       5. , 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5. , 5.5, 4.9, 4.4,\n",
       "       5.1, 5. , 4.5, 4.4, 5. , 5.1, 4.8, 5.1, 4.6, 5.3, 5. , 7. , 6.4,\n",
       "       6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5. , 5.9, 6. , 6.1, 5.6,\n",
       "       6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7,\n",
       "       6. , 5.7, 5.5, 5.5, 5.8, 6. , 5.4, 6. , 6.7, 6.3, 5.6, 5.5, 5.5,\n",
       "       6.1, 5.8, 5. , 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3,\n",
       "       6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5,\n",
       "       7.7, 7.7, 6. , 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2,\n",
       "       7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6. , 6.9, 6.7, 6.9, 5.8,\n",
       "       6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Akses kolom sepal.length\n",
    "df['sepal.length'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Akses hanya nilai semua kolom\n",
    "feature = df[['sepal.length', 'sepal.width', 'petal.length', 'petal.width']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Akses label\n",
    "label = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubah ke numpy array\n",
    "x = np.array(feature)\n",
    "y = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{x-mean}{std}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mencari rata-rata per kolom / per atribut\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "atribut_mean = x.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "atribut_std = x.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.38535265e+00,  3.28414053e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.50652052e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.24920112e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-5.37177559e-01,  1.93979142e+00, -1.16971425e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.50652052e+00,  7.88807586e-01, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.02184904e+00,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.74885626e+00, -3.62176246e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-5.37177559e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00,  7.88807586e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-1.87002413e+00, -1.31979479e-01, -1.51073881e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-5.25060772e-02,  2.16998818e+00, -1.45390138e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.73673948e-01,  3.09077525e+00, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-5.37177559e-01,  1.93979142e+00, -1.39706395e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.73673948e-01,  1.70959465e+00, -1.16971425e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.28338910e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-5.37177559e-01,  7.88807586e-01, -1.16971425e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.50652052e+00,  1.24920112e+00, -1.56757623e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  5.58610819e-01, -1.16971425e+00,\n",
       "        -9.20547742e-01],\n",
       "       [-1.26418478e+00,  7.88807586e-01, -1.05603939e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00, -1.31979479e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  7.88807586e-01, -1.22655167e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-7.79513300e-01,  1.01900435e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-7.79513300e-01,  7.88807586e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.38535265e+00,  3.28414053e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00,  9.82172869e-02, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-5.37177559e-01,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-7.79513300e-01,  2.40018495e+00, -1.28338910e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-4.16009689e-01,  2.63038172e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  3.28414053e-01, -1.45390138e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-4.16009689e-01,  1.01900435e+00, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  1.24920112e+00, -1.34022653e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-1.74885626e+00, -1.31979479e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.01900435e+00, -1.39706395e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.62768839e+00, -1.74335684e+00, -1.39706395e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.74885626e+00,  3.28414053e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.01900435e+00, -1.22655167e+00,\n",
       "        -7.88915558e-01],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.05603939e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.50652052e+00,  3.28414053e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-6.58345429e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  5.58610819e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [ 1.40150837e+00,  3.28414053e-01,  5.35408562e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 6.74501145e-01,  3.28414053e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  6.49083415e-01,\n",
       "         3.95774101e-01],\n",
       "       [-4.16009689e-01, -1.74335684e+00,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 7.95669016e-01, -5.92373012e-01,  4.78571135e-01,\n",
       "         3.95774101e-01],\n",
       "       [-1.73673948e-01, -5.92373012e-01,  4.21733708e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01,  5.58610819e-01,  5.35408562e-01,\n",
       "         5.27406285e-01],\n",
       "       [-1.14301691e+00, -1.51316008e+00, -2.60315415e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 9.16836886e-01, -3.62176246e-01,  4.78571135e-01,\n",
       "         1.32509732e-01],\n",
       "       [-7.79513300e-01, -8.22569778e-01,  8.07091462e-02,\n",
       "         2.64141916e-01],\n",
       "       [-1.02184904e+00, -2.43394714e+00, -1.46640561e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 6.86617933e-02, -1.31979479e-01,  2.51221427e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.89829664e-01, -1.97355361e+00,  1.37546573e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 3.10997534e-01, -3.62176246e-01,  5.35408562e-01,\n",
       "         2.64141916e-01],\n",
       "       [-2.94841818e-01, -3.62176246e-01, -8.98031345e-02,\n",
       "         1.32509732e-01],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  3.64896281e-01,\n",
       "         2.64141916e-01],\n",
       "       [-2.94841818e-01, -1.31979479e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  1.94384000e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 4.32165405e-01, -1.97355361e+00,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-2.94841818e-01, -1.28296331e+00,  8.07091462e-02,\n",
       "        -1.30754636e-01],\n",
       "       [ 6.86617933e-02,  3.28414053e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 3.10997534e-01, -5.92373012e-01,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01, -1.28296331e+00,  6.49083415e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 3.10997534e-01, -5.92373012e-01,  5.35408562e-01,\n",
       "         8.77547895e-04],\n",
       "       [ 6.74501145e-01, -3.62176246e-01,  3.08058854e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 9.16836886e-01, -1.31979479e-01,  3.64896281e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 1.15917263e+00, -5.92373012e-01,  5.92245988e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 1.03800476e+00, -1.31979479e-01,  7.05920842e-01,\n",
       "         6.59038469e-01],\n",
       "       [ 1.89829664e-01, -3.62176246e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-1.73673948e-01, -1.05276654e+00, -1.46640561e-01,\n",
       "        -2.62386821e-01],\n",
       "       [-4.16009689e-01, -1.51316008e+00,  2.38717193e-02,\n",
       "        -1.30754636e-01],\n",
       "       [-4.16009689e-01, -1.51316008e+00, -3.29657076e-02,\n",
       "        -2.62386821e-01],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  8.07091462e-02,\n",
       "         8.77547895e-04],\n",
       "       [ 1.89829664e-01, -8.22569778e-01,  7.62758269e-01,\n",
       "         5.27406285e-01],\n",
       "       [-5.37177559e-01, -1.31979479e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.89829664e-01,  7.88807586e-01,  4.21733708e-01,\n",
       "         5.27406285e-01],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  5.35408562e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 5.53333275e-01, -1.74335684e+00,  3.64896281e-01,\n",
       "         1.32509732e-01],\n",
       "       [-2.94841818e-01, -1.31979479e-01,  1.94384000e-01,\n",
       "         1.32509732e-01],\n",
       "       [-4.16009689e-01, -1.28296331e+00,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [-4.16009689e-01, -1.05276654e+00,  3.64896281e-01,\n",
       "         8.77547895e-04],\n",
       "       [ 3.10997534e-01, -1.31979479e-01,  4.78571135e-01,\n",
       "         2.64141916e-01],\n",
       "       [-5.25060772e-02, -1.05276654e+00,  1.37546573e-01,\n",
       "         8.77547895e-04],\n",
       "       [-1.02184904e+00, -1.74335684e+00, -2.60315415e-01,\n",
       "        -2.62386821e-01],\n",
       "       [-2.94841818e-01, -8.22569778e-01,  2.51221427e-01,\n",
       "         1.32509732e-01],\n",
       "       [-1.73673948e-01, -1.31979479e-01,  2.51221427e-01,\n",
       "         8.77547895e-04],\n",
       "       [-1.73673948e-01, -3.62176246e-01,  2.51221427e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 4.32165405e-01, -3.62176246e-01,  3.08058854e-01,\n",
       "         1.32509732e-01],\n",
       "       [-9.00681170e-01, -1.28296331e+00, -4.30827696e-01,\n",
       "        -1.30754636e-01],\n",
       "       [-1.73673948e-01, -5.92373012e-01,  1.94384000e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01,  5.58610819e-01,  1.27429511e+00,\n",
       "         1.71209594e+00],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.52267624e+00, -1.31979479e-01,  1.21745768e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 5.53333275e-01, -3.62176246e-01,  1.04694540e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  1.16062026e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 2.12851559e+00, -1.31979479e-01,  1.61531967e+00,\n",
       "         1.18556721e+00],\n",
       "       [-1.14301691e+00, -1.28296331e+00,  4.21733708e-01,\n",
       "         6.59038469e-01],\n",
       "       [ 1.76501198e+00, -3.62176246e-01,  1.44480739e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 1.03800476e+00, -1.28296331e+00,  1.16062026e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 1.64384411e+00,  1.24920112e+00,  1.33113254e+00,\n",
       "         1.71209594e+00],\n",
       "       [ 7.95669016e-01,  3.28414053e-01,  7.62758269e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 6.74501145e-01, -8.22569778e-01,  8.76433123e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.15917263e+00, -1.31979479e-01,  9.90107977e-01,\n",
       "         1.18556721e+00],\n",
       "       [-1.73673948e-01, -1.28296331e+00,  7.05920842e-01,\n",
       "         1.05393502e+00],\n",
       "       [-5.25060772e-02, -5.92373012e-01,  7.62758269e-01,\n",
       "         1.58046376e+00],\n",
       "       [ 6.74501145e-01,  3.28414053e-01,  8.76433123e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  9.90107977e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 2.24968346e+00,  1.70959465e+00,  1.67215710e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 2.24968346e+00, -1.05276654e+00,  1.78583195e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 1.89829664e-01, -1.97355361e+00,  7.05920842e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.28034050e+00,  3.28414053e-01,  1.10378283e+00,\n",
       "         1.44883158e+00],\n",
       "       [-2.94841818e-01, -5.92373012e-01,  6.49083415e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 2.24968346e+00, -5.92373012e-01,  1.67215710e+00,\n",
       "         1.05393502e+00],\n",
       "       [ 5.53333275e-01, -8.22569778e-01,  6.49083415e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 1.64384411e+00,  3.28414053e-01,  1.27429511e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 4.32165405e-01, -5.92373012e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 3.10997534e-01, -1.31979479e-01,  6.49083415e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 1.64384411e+00, -1.31979479e-01,  1.16062026e+00,\n",
       "         5.27406285e-01],\n",
       "       [ 1.88617985e+00, -5.92373012e-01,  1.33113254e+00,\n",
       "         9.22302838e-01],\n",
       "       [ 2.49201920e+00,  1.70959465e+00,  1.50164482e+00,\n",
       "         1.05393502e+00],\n",
       "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 5.53333275e-01, -5.92373012e-01,  7.62758269e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 3.10997534e-01, -1.05276654e+00,  1.04694540e+00,\n",
       "         2.64141916e-01],\n",
       "       [ 2.24968346e+00, -1.31979479e-01,  1.33113254e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 5.53333275e-01,  7.88807586e-01,  1.04694540e+00,\n",
       "         1.58046376e+00],\n",
       "       [ 6.74501145e-01,  9.82172869e-02,  9.90107977e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.89829664e-01, -1.31979479e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  9.33270550e-01,\n",
       "         1.18556721e+00],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  1.04694540e+00,\n",
       "         1.58046376e+00],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  7.62758269e-01,\n",
       "         1.44883158e+00],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.15917263e+00,  3.28414053e-01,  1.21745768e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
       "         1.71209594e+00],\n",
       "       [ 1.03800476e+00, -1.31979479e-01,  8.19595696e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 5.53333275e-01, -1.28296331e+00,  7.05920842e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  8.19595696e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 4.32165405e-01,  7.88807586e-01,  9.33270550e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 6.86617933e-02, -1.31979479e-01,  7.62758269e-01,\n",
       "         7.90670654e-01]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_norm, y, test_size=0.25, stratify=y, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat blueprint model\n",
    "model = Sequential()\n",
    "\n",
    "# Tentukan layer per model\n",
    "model.add(Dense(64, input_dim=4, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Tentukan loss, algoritma belajar, dan jenis evaluasi\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 1.1008 - accuracy: 0.3036 - val_loss: 1.0220 - val_accuracy: 0.4474\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9958 - accuracy: 0.5357 - val_loss: 0.9374 - val_accuracy: 0.5789\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9100 - accuracy: 0.6786 - val_loss: 0.8686 - val_accuracy: 0.7632\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8377 - accuracy: 0.8036 - val_loss: 0.8117 - val_accuracy: 0.7632\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7762 - accuracy: 0.8482 - val_loss: 0.7638 - val_accuracy: 0.7895\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7242 - accuracy: 0.8482 - val_loss: 0.7205 - val_accuracy: 0.7632\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.8571 - val_loss: 0.6821 - val_accuracy: 0.7632\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6419 - accuracy: 0.8482 - val_loss: 0.6475 - val_accuracy: 0.7632\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.8482 - val_loss: 0.6169 - val_accuracy: 0.7632\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5744 - accuracy: 0.8393 - val_loss: 0.5897 - val_accuracy: 0.7632\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.8393 - val_loss: 0.5641 - val_accuracy: 0.7632\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5161 - accuracy: 0.8482 - val_loss: 0.5404 - val_accuracy: 0.7895\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.8482 - val_loss: 0.5192 - val_accuracy: 0.7895\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.8482 - val_loss: 0.5002 - val_accuracy: 0.7895\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8482 - val_loss: 0.4832 - val_accuracy: 0.7895\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8482 - val_loss: 0.4675 - val_accuracy: 0.7895\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8750 - val_loss: 0.4532 - val_accuracy: 0.7895\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3774 - accuracy: 0.8839 - val_loss: 0.4404 - val_accuracy: 0.7895\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3592 - accuracy: 0.8929 - val_loss: 0.4286 - val_accuracy: 0.7895\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.9196 - val_loss: 0.4169 - val_accuracy: 0.7895\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.9286 - val_loss: 0.4067 - val_accuracy: 0.7895\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.9375 - val_loss: 0.3979 - val_accuracy: 0.7895\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2908 - accuracy: 0.9375 - val_loss: 0.3922 - val_accuracy: 0.7895\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2748 - accuracy: 0.9375 - val_loss: 0.3839 - val_accuracy: 0.7895\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2611 - accuracy: 0.9375 - val_loss: 0.3744 - val_accuracy: 0.7895\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.9375 - val_loss: 0.3678 - val_accuracy: 0.7895\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2360 - accuracy: 0.9375 - val_loss: 0.3621 - val_accuracy: 0.7895\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2252 - accuracy: 0.9375 - val_loss: 0.3569 - val_accuracy: 0.8158\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2151 - accuracy: 0.9464 - val_loss: 0.3516 - val_accuracy: 0.8158\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2048 - accuracy: 0.9464 - val_loss: 0.3473 - val_accuracy: 0.8158\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1955 - accuracy: 0.9554 - val_loss: 0.3433 - val_accuracy: 0.8158\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1877 - accuracy: 0.9643 - val_loss: 0.3392 - val_accuracy: 0.8421\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.9643 - val_loss: 0.3322 - val_accuracy: 0.8684\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1714 - accuracy: 0.9643 - val_loss: 0.3256 - val_accuracy: 0.8684\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1635 - accuracy: 0.9732 - val_loss: 0.3195 - val_accuracy: 0.8684\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1559 - accuracy: 0.9732 - val_loss: 0.3138 - val_accuracy: 0.8684\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1495 - accuracy: 0.9643 - val_loss: 0.3088 - val_accuracy: 0.8684\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9643 - val_loss: 0.3027 - val_accuracy: 0.8684\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1369 - accuracy: 0.9732 - val_loss: 0.2967 - val_accuracy: 0.8684\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1310 - accuracy: 0.9732 - val_loss: 0.2927 - val_accuracy: 0.8684\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9732 - val_loss: 0.2882 - val_accuracy: 0.8684\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1207 - accuracy: 0.9732 - val_loss: 0.2838 - val_accuracy: 0.8684\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9732 - val_loss: 0.2786 - val_accuracy: 0.8684\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9732 - val_loss: 0.2744 - val_accuracy: 0.8684\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.9732 - val_loss: 0.2700 - val_accuracy: 0.8684\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9732 - val_loss: 0.2638 - val_accuracy: 0.8684\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9732 - val_loss: 0.2594 - val_accuracy: 0.8684\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0963 - accuracy: 0.9732 - val_loss: 0.2570 - val_accuracy: 0.8684\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0934 - accuracy: 0.9732 - val_loss: 0.2547 - val_accuracy: 0.8684\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9732 - val_loss: 0.2509 - val_accuracy: 0.8684\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0874 - accuracy: 0.9821 - val_loss: 0.2464 - val_accuracy: 0.8684\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9821 - val_loss: 0.2407 - val_accuracy: 0.8947\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9732 - val_loss: 0.2369 - val_accuracy: 0.8947\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0795 - accuracy: 0.9732 - val_loss: 0.2330 - val_accuracy: 0.8947\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9821 - val_loss: 0.2305 - val_accuracy: 0.8947\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9821 - val_loss: 0.2283 - val_accuracy: 0.8947\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9821 - val_loss: 0.2245 - val_accuracy: 0.8947\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9821 - val_loss: 0.2219 - val_accuracy: 0.8947\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9821 - val_loss: 0.2191 - val_accuracy: 0.8947\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9821 - val_loss: 0.2162 - val_accuracy: 0.8947\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.9911 - val_loss: 0.2132 - val_accuracy: 0.8947\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9911 - val_loss: 0.2114 - val_accuracy: 0.8947\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9911 - val_loss: 0.2063 - val_accuracy: 0.9211\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9911 - val_loss: 0.2036 - val_accuracy: 0.9211\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9911 - val_loss: 0.1994 - val_accuracy: 0.9211\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9911 - val_loss: 0.1961 - val_accuracy: 0.9211\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.9911 - val_loss: 0.1921 - val_accuracy: 0.9211\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.9911 - val_loss: 0.1885 - val_accuracy: 0.9211\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.9911 - val_loss: 0.1859 - val_accuracy: 0.9211\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9911 - val_loss: 0.1839 - val_accuracy: 0.9211\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9911 - val_loss: 0.1822 - val_accuracy: 0.9211\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9911 - val_loss: 0.1820 - val_accuracy: 0.9211\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0481 - accuracy: 0.9911 - val_loss: 0.1805 - val_accuracy: 0.9211\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9911 - val_loss: 0.1793 - val_accuracy: 0.9211\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9911 - val_loss: 0.1779 - val_accuracy: 0.9211\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9911 - val_loss: 0.1749 - val_accuracy: 0.9211\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9911 - val_loss: 0.1721 - val_accuracy: 0.9211\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9911 - val_loss: 0.1704 - val_accuracy: 0.9211\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.9911 - val_loss: 0.1697 - val_accuracy: 0.9211\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9911 - val_loss: 0.1664 - val_accuracy: 0.9211\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9911 - val_loss: 0.1638 - val_accuracy: 0.9211\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9911 - val_loss: 0.1634 - val_accuracy: 0.9211\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9911 - val_loss: 0.1608 - val_accuracy: 0.9211\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 0.9911 - val_loss: 0.1586 - val_accuracy: 0.9211\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9911 - val_loss: 0.1572 - val_accuracy: 0.9211\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9911 - val_loss: 0.1577 - val_accuracy: 0.9211\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9911 - val_loss: 0.1572 - val_accuracy: 0.9211\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.1572 - val_accuracy: 0.9211\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.9911 - val_loss: 0.1540 - val_accuracy: 0.9211\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9911 - val_loss: 0.1521 - val_accuracy: 0.9211\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9911 - val_loss: 0.1499 - val_accuracy: 0.9211\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9211\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9211\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9211\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.1462 - val_accuracy: 0.9211\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9211\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9211\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 0.1470 - val_accuracy: 0.9211\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9911 - val_loss: 0.1478 - val_accuracy: 0.9211\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 0.1476 - val_accuracy: 0.9211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x4465e31ee0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isi data ke neural network dan train\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal.length          6.3\n",
       "sepal.width           3.3\n",
       "petal.length            6\n",
       "petal.width           2.5\n",
       "variety         Virginica\n",
       "label                   2\n",
       "Name: 100, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menggunakan data dari df\n",
    "df.iloc[100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [[6.3, 3.3, 6, 2.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.array(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3, 3.3, 6. , 2.5]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.84333333, 3.05733333, 3.758     , 1.19933333])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atribut_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82530129, 0.43441097, 1.75940407, 0.75969263])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atribut_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal.length', 'sepal.width', 'petal.length', 'petal.width', 'variety',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal.length          6.3\n",
       "sepal.width           3.3\n",
       "petal.length            6\n",
       "petal.width           2.5\n",
       "variety         Virginica\n",
       "label                   2\n",
       "Name: 100, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{x-mean}{std}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepalLength = (6.3 - atribut_mean[0]) / atribut_std[0]\n",
    "sepalWidth = (3.3 - atribut_mean[1]) / atribut_std[1]\n",
    "petalLength = (6 - atribut_mean[2]) / atribut_std[2]\n",
    "petalWidth = (2.5 - atribut_mean[3]) / atribut_std[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "xPred = np.array([[sepalLength, sepalWidth, petalLength, petalWidth]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil = model.predict(xPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.7841011e-06, 5.7797355e-04, 9.9941528e-01]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(hasil, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
